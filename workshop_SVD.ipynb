{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb35cff1",
   "metadata": {},
   "source": [
    "# Multidimensional Data and Singular Value Decomposition (SVD)\n",
    "Author: Briony Yorke\n",
    "\n",
    "In this workshop we will look at advanced methods to analyse multidimensional data. We will first revisit the idea of matrices and vectors and then we will look at *singular value decomposition* (SVD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05626dab",
   "metadata": {},
   "source": [
    "\n",
    "## Multidimensional Data\n",
    "\n",
    "Scientific measurements often give us a set of numbers for each experiment.\n",
    "For example:\n",
    "\n",
    "- A spectrum with intensity at 1000 wavelengths\n",
    "\n",
    "- A time-resolved signal measured at 200 timepoints\n",
    "\n",
    "- An image with many pixels\n",
    "\n",
    "- A sensor recording several channels at once\n",
    "\n",
    "Each measurement is simply a list of numbers ‚Äî a vector.\n",
    "\n",
    "If you repeat the measurement many times (different samples or conditions), we can stack these vectors into a table:\n",
    "\n",
    "Each row is one measurement\n",
    "\n",
    "Each column is one variable (wavelength, timepoint, pixel, etc.)\n",
    "\n",
    "For example:\n",
    "If you take 10 spectra, each with 1000 wavelengths, your data becomes a table with 10 columns and 1000 rows:\n",
    "\n",
    "A 10 √ó 1000 matrix.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e7720",
   "metadata": {},
   "source": [
    "\n",
    "### Organising Data with Matrices\n",
    "A matrix is a convenient way to store several measurements together. We have already seen an example of matrix in the last workshop. We will be using atmospheric data again - this is multidimensional and includes measurements relating to local meteorology, such as temperature, pressure, wind speed, and wind direction, as well as measurements of the chemical composition of the atmosphere which includes concentrations of ozone, nitrogen oxides, hydrocarbons and the radicals OH and HO<sub>2</sub>.\n",
    "\n",
    "Run the code cell below to import the packages you will use in this workshop and to import the data as a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "file_url = 'http://homepages.see.leeds.ac.uk/~chmdst/big_data/Workshop4/clearflo_summer2012_15min_merge.csv'\n",
    "df = pd.read_csv(file_url) # the header and delimiter are the defaults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623dc2f",
   "metadata": {},
   "source": [
    "Next you can check the determine and output size of the matrix (or dataframe) using the df.head() command in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17108ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "__.____()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19be12",
   "metadata": {},
   "source": [
    "To analyse the data in this table we will first remove any columns that do not contain numeric data (e.g. day_and_time).\n",
    "\n",
    "We need to prepare the dataframe so that is only contains numeric data. To do this we will generate a new dataframe using the command ```df.select_dtypes``` and selecting columns that are numbers ```np.number```. \n",
    "\n",
    "Modify the cell below to generate a dataframe containing only numeric data and print the column headings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0087a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "\n",
    "numeric_df = ___.____(include=[___.___])\n",
    "\n",
    "print(\"Numeric columns:\",____.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370afd4",
   "metadata": {},
   "source": [
    "#### Pearson Correlation Coefficients\n",
    "\n",
    "Our atmospheric data contains many variables, some of which correlate and others which are unrelated. We can quickly investigate correlations between pairs of variables by calculating the Pearson correlation coefficient.\n",
    "\n",
    "The Pearson correlation coefficient is:\n",
    "\n",
    "$\\rho=\\frac{cov(X/Y)}{\\sigma_x\\sigma_y}$\n",
    "\n",
    "Where Cov(X,Y) is the covariance between two variables X and Y, the covariance is a measure of how two variables vary together. It gives you an idea of whether increases in one variable correspond to increases or decreases in another. $\\sigma$ are the standard deviations of each varaible. \n",
    "\n",
    "\n",
    "- $\\rho$ = 1 is a perfect positive correlation\n",
    "- $\\rho$ = -1 is a perfect negative correlation\n",
    "- $\\rho$ = 0 is no correlation\n",
    "\n",
    "In the code cell below calculate the pairwise pearson correlation coefficients from the numeric dataframe ```numeric_df``` using the command ```corr_matrix=numeric_df.corr()```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "____ = _____.____()  # Pearson correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39963a1",
   "metadata": {},
   "source": [
    "An effective way of visualising these correlations is to plot a **heatmap**. Heatmaps are a 2-dimensional data visualization technique that represent the magnitude of individual values within a matrix as a colour. Seaborn has an inbuilt heatmap function ```sns.heatmap```.\n",
    "\n",
    "In the cell below use pandas to make a list of the column headers using the command ```df.columns.tolist()```. Then use  ```sns.heatmap``` to plot the correlation matrix ```corr_matrix``` using the colourmap (cmap) 'coolwarm', use the column headers as the y-ticklabels and x-ticklabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers= ____.____.____\n",
    "\n",
    "plt.figure(figsize=(11, 9)) \n",
    "sns.heatmap(corr_matrix, cmap='___', yticklabels=___, xticklabels=___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0eba60",
   "metadata": {},
   "source": [
    "The diagonal line in the heat map shows that the variables perfectly correlate with themselves - this is exactly what we expect. The red regions in the heat map indicate where there is a strong colleration between variables, the pale colours indicate where there is no correlation (0.2 to -0.2).\n",
    "\n",
    "The image below shows a section of the heat map highlighting a positive correlation between acetylene and ethene.\n",
    "\n",
    "<img src=\"heatmap.png\" height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98070b3b",
   "metadata": {},
   "source": [
    "Ethene and acetylene have shared emission sources including:\n",
    "\n",
    "- Vehicle exhaust\n",
    "\n",
    "- Industrial combustion\n",
    "\n",
    "- Biomass burning\n",
    "\n",
    "- Natural gas leakage\n",
    "\n",
    "- Petrochemical activity\n",
    "\n",
    "So the positive correlation between C‚ÇÇH‚ÇÇ and C‚ÇÇH‚ÇÑ reflects shared emissions. The composition of the atmosphere is determined by complex chemistry, there are many different shared emission sources and chemical reactions that are dependent on multiple reagents, temperature and sun light. The chemical reactions are dependent on the emissions sources and one another. That means that the underlying chemistry that determines the atmospheric composition is multidimensional.\n",
    "\n",
    "The correlation coefficient only shows us the relationship between pairs or variables, but understanding the relationship multiple variables is more complex.\n",
    "\n",
    "Large scientific datasets often contain:\n",
    "\n",
    "- Redundant information\n",
    "\n",
    "- Noise\n",
    "\n",
    "- Correlated variables\n",
    "\n",
    "- A few ‚Äútrue‚Äù underlying features\n",
    "\n",
    "\n",
    "Think of each variable as an axis, just like in 2 dimensions where we have an x-axis and y-axis, but now you have many axes:\n",
    "\n",
    "O<sub>3</sub> axis, CO axis, NO axis,RO<sub>2</sub> axis etc ...\n",
    "\n",
    "A single measurement is a point inside this huge multi-axis space.\n",
    "\n",
    "A scatter plot usually only shows two dimensions x and y, we can visualise an additional dimension by using a colour map. Modify the code cell below to generate a scatter plot showing variation in O<sub>3</sub> / ppbv, CO /ppbv and PAN /pptv. This code uses the sns.scatterplot command from seaborn, seaborn is a package which can aid in data visualisation. It is especially useful for applying colour palettes (hue) to data, in this case we will use the palette called 'viridis'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=___, x='___', y='___', hue='___', palette='___', s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3fcdb",
   "metadata": {},
   "source": [
    "Now try adding extra dimension by changing the size of the spots to correspond to temperature ```Temp / oC``` using the ```size=``` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=___, x='___', y='___', hue='___', size='___', palette='_____', sizes=(5,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e36de",
   "metadata": {},
   "source": [
    "#### Checking our data\n",
    "This doesn't look quite right - by plotting our data against temperature you can see there is some problem with the temperature column. The range of values is very low, we would never measure a temperature of -9000 <sup>o</sup>C. This shows us that data visualisation is very important not only to identify trends but also to find problems in our data that may not be obvious.\n",
    "\n",
    "Let's quickly check our data. Modify the cell below to check the data format \"dtype\", the minimum \"min\" and maximum \"max\" values in the Temp / oC column and plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the variable column and the column Temp / oC from the dataframe called numeric_df.\n",
    "col = ___['___']\n",
    "\n",
    "#print the datatype\n",
    "print(\"dtype:\", col.dtype)\n",
    "#print the minimum value\n",
    "print(\"min:\", col.min())\n",
    "#print the maximum value\n",
    "print(\"___:\", ___.___())\n",
    "\n",
    "#plot the data\n",
    "plt.figure()\n",
    "plt.plot(___)\n",
    "#set the title\n",
    "____.____(\"Temperature check\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ff5db",
   "metadata": {},
   "source": [
    "You can see that there are some outliers. We will remove the rows containing the outliers to simplify our data analysis. We will remove the rows from the data frame not the raw data - even the outliers may be important and should be preserved in the raw data.\n",
    "\n",
    "First we need to determine which values are outliers, for this purpose can use the **z-value**. The z-value is a statistical measure that determines how many standard deviations a data point is from the mean:\n",
    "\n",
    "z = (x - mean) / std\n",
    "\n",
    "Run the cell below to use the stats.zscore command from the scipy stats package to calculate z-scores and then plot the z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the z-score for temperature\n",
    "zscore = np.abs((col - col.mean()) / col.std())\n",
    "\n",
    "\n",
    "# Plot z-scores as a scatter chart\n",
    "plt.plot(zscore)\n",
    "#set the title\n",
    "plt.title(\"Zscores\")\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Z-Score\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fd4be",
   "metadata": {},
   "source": [
    "We can now set a threshold for the z-score based off our graph, we can see that there are only a few outliers and the z-score of these are much greater than 2 standard deviations, count how many outliers are present and remove them from the dataframe.\n",
    "\n",
    "Modify the code below to:\n",
    "\n",
    "1. Define threshold as 2 standard deviations away from the mean (z-score = 2).\n",
    "2. Define outliers in ```numeric_df``` as values with ```zscore > threshold```.\n",
    "3. Print a list of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define threshold\n",
    "threshold = ___\n",
    "#define outliers\n",
    "outliers = ___[___ > ___]\n",
    "\n",
    "# Print the outliers\n",
    "\n",
    "print(____)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2768ee",
   "metadata": {},
   "source": [
    "We can see there are 21 outliers to remove. To do this we will make a clean version of the data by making a new dataframe which only contains rows where the temperature is within 2 standard deviations of the mean.\n",
    ">```python\n",
    "> df_clean_temp = numeric_df[z < threshold]\n",
    ">```\n",
    "\n",
    "We will then check that 21 rows have been removed using the df.shape command to see the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_temp = ___[___]   # keep points within ¬±2œÉ\n",
    "df_clean_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96571f0a",
   "metadata": {},
   "source": [
    "Now use the cell below to remove outliers in the solar power columns ```'Solar / Wm-2'``` you only need to repeat the z-score calculation, determine a sensible threshold and remove the columns where the z-score is more than 2 standard deviations away from the mean and generate a new dataframe called ```df_clean```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782556ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the variable column and the column Solar / Wm-2 from the dataframe called df_clean_temp.\n",
    "col2 = ____-[_____]\n",
    "\n",
    "# Calculate the z-score for temperature\n",
    "zscore_solar = ____((____ - ____) / _____)\n",
    "\n",
    "\n",
    "# Plot z-scores as a scatter chart\n",
    "___.___(____)\n",
    "#set the title\n",
    "___.___(\"___\")\n",
    "#set the x-axis label\n",
    "___.x___(\"___\")\n",
    "#set the y-axis label\n",
    "plt.ylabel(\"___\")\n",
    "#show the plot\n",
    "__.__()\n",
    "\n",
    "#define threshold\n",
    "threshold = ___\n",
    "#define outliers\n",
    "outliers = ____[____]\n",
    "\n",
    "df_clean = ___[___< ___]   # keep points within the threshold standard deviation\n",
    "\n",
    "#output the shape of the dataframe\n",
    "‚Äì‚Äì‚Äì.___\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8fde8",
   "metadata": {},
   "source": [
    "Now we have removed the outliers, let's retry making the plot where the temperature determines the size of the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed65dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_clean, x='O3 / ppbv', y='CO / ppbv', hue='PAN / pptv', size='Temp / oC', palette='viridis', sizes=(5,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abaf70d",
   "metadata": {},
   "source": [
    "Now we can get a better idea of trends in the data but this is still difficult to see and describe correlations between different variables. Since there are a huge number of variables in our data table (or matrix) the task of looking for correlations between different variables becomes even more difficult. Our plot is currently 4 dimensional, adding more dimensions would make it very difficult to interpret. Imagine if you wanted to find correlations between 1000s of variables - how can you do this quickly?\n",
    "\n",
    "We can better understand our data using methods that delve into patterns or trends in our matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355b527",
   "metadata": {},
   "source": [
    "#### Clusters\n",
    "When you plot all measurements (even if you can‚Äôt visualize many dimensions), the points form some cloud-like shape or **cluster**. These can be elongated, flat, curved, thick in some directions and thin in others. In the plot above you may notice 'clustering' in the colours and it is possible to identify more structure in the data.\n",
    "\n",
    "A ‚Äúdirection‚Äù is a line through the cloud or cluster. In principle component analysis and singular value decomposition this means a specific orientation in this multi-dimensional space. In 2D, a ‚Äúdirection‚Äù is just a line: ‚ÜóÔ∏é or ‚ÜòÔ∏é or horizontal or vertical. In 3D, it could be any vector inside the space. In multiple dimensions, it‚Äôs still a vector ‚Äî just with a long list of coefficients.\n",
    "\n",
    "You can think of this as rotating and moving the axes to find directions that show underlying relationships in the data.The directions are not necessarily aligned with one variable.\n",
    "\n",
    "Imagine rotating a ruler inside your cloud of data, trying to find where the data spreads out the most.\n",
    "\n",
    "The direction of maximum spread = 1st singular vector\n",
    "\n",
    "The next-most-spread direction = 2nd singular vector\n",
    "\n",
    "etc.\n",
    "\n",
    "These directions are orthogonal (independent).\n",
    "\n",
    "#### Why These Directions Matter\n",
    "They reveal structure you don‚Äôt see by looking at raw variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509d30d",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "SVD helps us find the fundamental **directions** in the data. These are called **singular vectors**.\n",
    "\n",
    "SVD takes a matrix ùê¥ and rewrites it as:\n",
    "\n",
    "$ A = U S V^T$\n",
    "\n",
    "- V·µÄ contains the important directions in the data space. These explain how the data varies.\n",
    "\n",
    "- U contains the weights (how much each direction contributes to each observation).\n",
    "\n",
    "- S tells you the importance of each direction.\n",
    "\n",
    "Large singular values = strong structure\n",
    "Small singular values = noise\n",
    "\n",
    "So SVD does the following factorisation: \n",
    "\n",
    "data ‚Üí directions + strengths.\n",
    "\n",
    "Taking a single matrix and breaking it down into the product of two or more simpler matrices is called **factorisation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ae48c",
   "metadata": {},
   "source": [
    "Now let's look at a couple of example of factorisation, first we'll look at a very simple example.\n",
    "\n",
    "Then we'll use a matrix that produces an image - this is similar to the skills you have learned in our image processing workshop. \n",
    "\n",
    "Run the cell below to generate and visualise a simple matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24683a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [0, 0, 2, 2],\n",
    "    [0, 0, 2, 2]\n",
    "], dtype=float)\n",
    "\n",
    "plt.imshow(A, cmap='viridis')\n",
    "plt.title(\"Original Matrix A\")\n",
    "plt.colorbar();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b11c8",
   "metadata": {},
   "source": [
    "This matrix has two blocks:\n",
    "\n",
    "- one block of 1‚Äôs\n",
    "\n",
    "- one block of 2‚Äôs\n",
    "\n",
    "It can be factorised as: \n",
    "\n",
    "ùê¥ ‚âà ùêµùê∂\n",
    "\n",
    "where\n",
    "\n",
    "B is a 4√ó2 matrix and C is a 2√ó4 matrix.\n",
    "\n",
    "This means we want to explain the 4√ó4 matrix using only two hidden patterns (the block of 1's and the block of 2's).\n",
    "\n",
    "In the cell below we use a random seed to generate values for the elements of two matrices B and C. The rank tells us we are looking for 2 hidden patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73def52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "rank = 2   # number of hidden patterns\n",
    "\n",
    "B = np.random.rand(4, rank)\n",
    "C = np.random.rand(rank, 4)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(B, cmap='viridis')\n",
    "ax[0].set_title(\"Random B\")\n",
    "\n",
    "\n",
    "ax[1].imshow(C, cmap='viridis')\n",
    "ax[1].set_title(\"Random C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c19d78a",
   "metadata": {},
   "source": [
    "These random matrices are our first (random) guess but they do not satisfy the condition ùê¥ ‚âà ùêµùê∂, we can see this by multiplying matrices B and C using the @ symbol which performs matrix multiplication in NumPy. Run the cell below to reconstruct the matrix from the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pred = B@C\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(A, cmap='viridis')\n",
    "ax[0].set_title(\"Original A\")\n",
    "\n",
    "\n",
    "ax[1].imshow(A_pred, cmap='viridis')\n",
    "ax[1].set_title(\"Reconstructed A_pred\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b4577",
   "metadata": {},
   "source": [
    "A_pred does to look like our original matrix, we need to optimise the values in B and C so that we can reconstruct A.\n",
    "\n",
    "We can do this by minimising the error :\n",
    "\n",
    "error=‚à£‚à£A‚àíBC‚à£‚à£\n",
    "\n",
    "A simple way to do this is by using the gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01  # learning rate this is the step size taken to update the parameters\n",
    "\n",
    "for step in range(5000):\n",
    "    # current reconstruction\n",
    "    A_pred = B @ C\n",
    "\n",
    "    # error matrix\n",
    "    E = A - A_pred\n",
    "\n",
    "    # update rules\n",
    "    B += lr * (E @ C.T) # T is the transpose of the matrix - this flips the rows and columns to make sure B is the correct shape.\n",
    "    C += lr * (B.T @ E)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(B, cmap='viridis')\n",
    "ax[0].set_title(\"Best guess B\")\n",
    "\n",
    "\n",
    "ax[1].imshow(C, cmap='viridis')\n",
    "ax[1].set_title(\"Best guess C\")\n",
    "\n",
    "# final reconstruction\n",
    "A_pred = B @ C\n",
    "\n",
    "# plot the matricees\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(A, cmap='viridis')\n",
    "ax[0].set_title(\"Original A\")\n",
    "\n",
    "ax[1].imshow(A_pred, cmap='viridis')\n",
    "ax[1].set_title(\"Reconstructed A_pred\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a2b3d",
   "metadata": {},
   "source": [
    "Now we can see that we have predicted the underlying matrices and the two factors B and C have be optimised to reveal the hidden patterns in the matrix.\n",
    "\n",
    "- one pattern corresponds to the ‚Äúblock of 1‚Äôs‚Äù\n",
    "\n",
    "- one pattern corresponds to the ‚Äúblock of 2‚Äôs‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6c561",
   "metadata": {},
   "source": [
    "Now you can try this yourself:\n",
    "\n",
    "Modify the cell below to generate a matrix called smiley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the matrix called smiley \n",
    "\n",
    "smiley = ___.___([\n",
    "    [0,0,1,1,1,1,0,0],\n",
    "    [0,1,0,0,0,0,1,0],\n",
    "    [1,0,1,0,0,1,0,1],\n",
    "    [1,0,0,0,0,0,0,1],\n",
    "    [1,0,1,0,0,1,0,1],\n",
    "    [1,0,0,1,1,0,0,1],\n",
    "    [0,1,0,0,0,0,1,0],\n",
    "    [0,0,1,1,1,1,0,0],\n",
    "])\n",
    "\n",
    "#plot the matrix as an image\n",
    "\n",
    "___.___(___, ___=\"___\")\n",
    "#choose a suitable title\n",
    "___.___(\"___\")\n",
    "___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b18e50",
   "metadata": {},
   "source": [
    "Generate 2 matrices $D$ and $F$ which have a size of 8 $\\times$ 2 elements from a random seed and optimise them to minimise error=‚à£‚à£A‚àíDF‚à£‚à£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "___.___.___(0)\n",
    "\n",
    "rank = ___   # number of hidden patterns\n",
    "\n",
    "D = ___.___.___(__, rank)\n",
    "F = ___.___.___(rank, ___)\n",
    "\n",
    "print(___)\n",
    "print (___)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ___  # learning rate this is a hyperparameter - the step size taken to update the parameters\n",
    "\n",
    "for ___ in ___(___):\n",
    "    # current reconstruction\n",
    "   ___ = ___ @ ___\n",
    "\n",
    "    # error matrix\n",
    "    E = ___ - ___\n",
    "\n",
    "    # update rules\n",
    "  ___ += lr * (E @ ___.T) # T is the transpose of the matrix - this flips the rows and columns to make sure B is the correct shape.\n",
    "  ___ += lr * (___.T @ E)\n",
    "\n",
    "# final reconstruction\n",
    "___ = ___ @ ___\n",
    "\n",
    "# plot the matricees smiley and smiley_pred using the viridis colour map\n",
    "\n",
    "___, ___ = ___.___(___, ___, ___=(8,4))\n",
    "\n",
    "ax[0].imshow(___, cmap='___')\n",
    "ax[0].set_title(\"Original Smiley\")\n",
    "\n",
    "ax[1].imshow(___, cmap='___')\n",
    "ax[1].set_title(\"Reconstructed smiley_pred\")\n",
    "\n",
    "___.___()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb78b8",
   "metadata": {},
   "source": [
    "You can see that the optimisation has not completely worked. The reconstructed matrix looks different to the original - we have not been able to learn the hidden pattern.\n",
    "\n",
    "Now let's compare this to the results that we can obtain using singular value decomposition.\n",
    "\n",
    "Remember in SVD:\n",
    "\n",
    "data ‚Üí directions + strengths.\n",
    "\n",
    "A = U S V·µÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute SVD\n",
    "U, S, VT = np.linalg.svd(smiley)\n",
    "\n",
    "print(\"U shape:\", U.shape) \n",
    "print(\"S shape:\", S.shape)\n",
    "print(\"VT shape:\", VT.shape)\n",
    "\n",
    "#Reconstruct the matrix using only the first k components\n",
    "def reconstruct(k):\n",
    "    return (U[:, :k] @ np.diag(S[:k]) @ VT[:k, :])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i,k in enumerate([1,2,4,8],1):\n",
    "    plt.subplot(1,4,i)\n",
    "    plt.imshow(reconstruct(k), cmap=\"viridis\")\n",
    "    plt.title(f\"k = {k}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Smiley Reconstructed With Increasing SVD Components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337214",
   "metadata": {},
   "source": [
    "\n",
    "Each SVD component is like a ‚Äúlayer‚Äù of the image. The first few components capture most of the structure.\n",
    "\n",
    "SVD gives the optimal factorisation:\n",
    "\n",
    "$ A = U S V^T $\n",
    "\n",
    "If you want a rank-k approximation, you just keep the top k singular values:\n",
    "\n",
    "$ A_k \\approx U_k‚ÄãS_kV_k^T$\n",
    "\n",
    "\n",
    "This gives the best possible approximation to A, with the smallest reconstruction error, in a single computation.\n",
    "\n",
    "### Why SVD is better than gradient descent\n",
    "\n",
    "- No hyperparameters (no learning rate, no iterations).\n",
    "\n",
    "- No risk of getting stuck at a bad solution.\n",
    "\n",
    "- Fast and stable (thanks to 50 years of numerical linear algebra research).\n",
    "\n",
    "- Error is provably minimal.\n",
    "\n",
    "- It is mathematically the correct factorisation.\n",
    "\n",
    "### Using SVD to analyse data\n",
    "\n",
    "Next we'll use SVD to analyse a toy spectral dataset before analysing the atmospheric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551eae99",
   "metadata": {},
   "source": [
    "Modify the cell below to:\n",
    "1. Generate toy spectra of three different chemicals, A, B and C.\n",
    "\n",
    ">```python\n",
    "> x = np.linspace(200, 400, 300) '''First define the x-axis of the spectra. We will plot spectra with 300 data points between 200 - 400 nm.'''\n",
    ">```\n",
    "\n",
    "We will then generate spectra for the three different components as gaussian functions using the formula:\n",
    "\n",
    "$Absorbance=Amplitude\\times exp{-\\frac{(\\lambda-\\lambda_{max})^2}{2\\sigma^2}}$\n",
    "\n",
    "Where: \n",
    "- $\\lambda$ is the wavelength\n",
    "- $\\lambda_{max}$ is the wavelength at peak absorbance\n",
    "- $\\sigma$ is the width of the absorbance peak.\n",
    "\n",
    "- Chemical A $\\lambda_{max}$ = 230 nm and amplitdue 1\n",
    "- Chemical B $\\lambda_{max}$ = 290 nm and amplitude 0.9\n",
    "- Chemical C $\\lambda_{max}$ = 340 nm and amplitude 0.6\n",
    "\n",
    "and $\\sigma$ should be between 25-30 for each component.\n",
    "\n",
    "Combine the three spectra into a 300 x 3 matrix using the vertical stack (vstack) command:\n",
    "\n",
    ">```python\n",
    ">  spectra = np.vstack([A, B, C]).T  '''# shape (300, 3) '''\n",
    ">```\n",
    "\n",
    "2. Define random weights to generate N = 200 random mixtures containing difference concentrations of the 3 chemicals. These weights alter the absorbance corresponding to an imagined change in concentration.\n",
    "\n",
    "3. Add noise using ```np.random.randn``` ensuring the noise is added to every element in the mixed_abs matrix using ```(*mixed_abs.shape)```\n",
    "4. Plot spectra of all the 200 random mixtures on one graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4236248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create 3 chemical \"spectra\"\n",
    "\n",
    "wl = np.linspace(180, 450, 300)\n",
    "\n",
    "A = np.exp(-(wl-230)**2 / (2 * 25**2))        # species A\n",
    "B = 0.9 * ___(-(___ - ___)**2 / (2 * ___**2))   # species B\n",
    "C = ___ * ___(-(___ - ___)**___ / (___ * ___**___))  # species C\n",
    "\n",
    "spectra = np.vstack([___, ___, ___]).T  # shape (300, 3)\n",
    "\n",
    " \n",
    "#  Mix them into 200 samples\n",
    "\n",
    "N = ___\n",
    "weights = np.random.rand(N, 3)   # random abundances\n",
    "mixed_abs = weights @ spectra.T           # resulting mixtures\n",
    "\n",
    "# Add noise\n",
    "mixed_abs += 0.2 * np.random.randn(___.___)\n",
    "\n",
    "# Plot all spectra\n",
    "\n",
    "# Create a magma palette with N colors\n",
    "\n",
    "palette = sns.color_palette(\"magma\", N)\n",
    "\n",
    "for i in range(N):\n",
    "    plt.plot(wl, mixed_abs[i], color=palette[i], alpha=0.6, linewidth=0.7)\n",
    "\n",
    "plt.title(\"Spectra of 200 mixtures\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Absorbance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26ee31",
   "metadata": {},
   "source": [
    "These data are very noisy, it is very difficult to interpret the underlying spectra of the chemical species contributing to the mixture, it is also very difficult to determine the relative abundance of each species, we may not even know how many species are present in the mixtures. \n",
    "\n",
    "If we were to record these spectra we can use SVD to quickly:\n",
    "1. Determine the number of chemical species in the mixtures.\n",
    "2. Denoise the spectra.\n",
    "3. Calculate the relative abundance of the components in each mixture.\n",
    "\n",
    "Let's see what happens when we perform singular value decomposition. \n",
    "\n",
    "An important first step in SVD is to subtract the 'mean spectrum' from all of the indivdual spectra. This is called **centering**, we do this to remove offsets in the baseline and to prevent the mean spectrum from dominating the first singular vector. This means we focus on the differences in the spectra allowing us to determine the directions with the maximum variation.\n",
    "\n",
    "To do this we make a new matrix called ```mixed_abs_centered``` which is equal to ```mixed_abs - np.mean(mixed_abs)``` we calculate the mean along each row of the matrix (spectrum) which is controlled by the ```axis=0``` command.\n",
    "\n",
    "Modify the cell below to center and perform SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Center the data\n",
    "\n",
    "mixed_abs_centered = mixed_abs - np.mean(mixed_abs, axis=0)\n",
    "\n",
    "# Perform SVD \n",
    "\n",
    "__, __, __ = ___.___.__(___, full_matrices=False)\n",
    "\n",
    "#print the first 5 singular values\n",
    "\n",
    "print(\"Singular values:\", S[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e851c",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- $U$ is the left singular vector, it contains information about how the abundance of each chemical in a sample.\n",
    "- $S$ are the singular values. These measure how much variance each SVD component describes. Bigger singular value = more important spectral feature. They determine the scale of the component in the SVD reconstruction. A few components usally dominate the dataset and these have singular values which are much bigger than those representing noise.\n",
    "- $V^T$  is the right singular vector, it is the shape basis vector over the 300 wavelengths. It contains information about the variance in the shape of the spectra.\n",
    "\n",
    "We can see that the first 3 singular values dominate the spectra - suggesting there are 3 components. \n",
    "\n",
    "Next we can use a ***scree plot*** to show how important each SVD mode is.\n",
    "The scree plot is a graph of the singular value based variance ($S^2$) against the singular value index (the component number)  a big drop after $S_3$ ‚Üí indicates three strong dominating components. The scree plots helps identify the rank ($k$) of our spectra. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each singular value relates to variance as S^2\n",
    "SVbased_variance = ___**___\n",
    "\n",
    "# Make the Scree plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Scree plot\n",
    "plt.plot(range(1, len(S)+1), SVbased_variance, marker='o', label='Variance explained')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Singular Value Index (Mode Number)\")\n",
    "plt.ylabel(\"Singular Value Based Variance \")\n",
    "plt.title(\"___\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a682",
   "metadata": {},
   "source": [
    "The scree plot confirms that the first 3 components from the SVD are dominant. We could easily see this from our singular values but scree plots are very useful when there are many dominant vectors.\n",
    "\n",
    "Now let's looks at the variance in the shape.\n",
    "\n",
    "Modify the code below to plot the first 5 right singular vectors ($V^T$) and the spectra of the individual chemicals A, B and C. This code cotains a command to normalise the vector (divide by the maximum value) which ensures the x-axis represents wavelength:\n",
    "\n",
    ">```python\n",
    ">  sv_norm = sv / np.max(np.abs(sv))  # normalize for plotting\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # number of singular vectors to plot\n",
    "\n",
    "# Plot first k singular vectors\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(k):\n",
    "    sv = VT[i]  # i-th singular vector\n",
    "    sv_norm = ___ / ___.___(__.__(___))  # normalize for comparison\n",
    "    plt.plot(wl, sv_norm, lw=2, label=f'SVD Vector {i+1}')\n",
    "\n",
    "plt.title(f\"Original Spectra and First {k} Singular Vectors\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Normalized Intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40152e84",
   "metadata": {},
   "source": [
    "We have performed SVD on the mixed spectra. The number of components was not defined but we can clearly see that the first 3 right singular vectors ($V^T$) contain information about the varience in shape of the spectra, where as the fourth and fifth right singular vectors are just noise. Using SVD we have found that there are 3 components (chemicals)  in the mixtures.\n",
    "\n",
    "Now modify the code cell below to plot the first 3 singular vectors and the spectra of the three chemicals A, B and C.\n",
    "\n",
    "Make sure you normalise the singular vector as well as the original chemical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c419741",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot original spectra\n",
    "plt.plot(wl, A/np.max(A), 'k--', lw=1, label='Original A')\n",
    "plt.plot(wl, B/np.max(B), 'k--', lw=1, label='Original B')\n",
    "plt.plot(wl, C/np.max(C), 'k--', lw=1, label='Original C')\n",
    "\n",
    "# Plot first k singular vectors\n",
    "k = ___\n",
    "for i in ___:\n",
    "    ___ = ___[i]  # i-th singular vector\n",
    "    ___ = ___ / ___.___(___.___(___))  # normalize for comparison\n",
    "    ___.___(___, ___, ___=___, ___=f'___')\n",
    "\n",
    "plt.title(f\"First {k} Singular Vectors\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Normalized Intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a373ec5",
   "metadata": {},
   "source": [
    "\n",
    "You can see that the first 3 singular vectors gives us an indication of $ \\lambda_{max}$ of the three chemicals. However, the SVD components do not perfectly match the original spectra of the three chemicals, they are oscillating patterns not Gaussians. \n",
    "\n",
    "This is because SVD rotates the mixture space into orthogonal axes.\n",
    "\n",
    "### What do we mean by orthogonal?\n",
    "Orthogonal means the dot product of two vectors is zero. For the first two right singular vectors from SVD, `VT[0]` and `VT[1]`\n",
    "\n",
    "${VT[0]} \\cdot \\text{VT[1]} = \\sum_{\\lambda=1}^{M} \\text{VT[0]}(\\lambda) \\, \\text{VT[1]}(\\lambda) = 0$\n",
    "\n",
    "where, M, is the number of wavelengths (elements in each vector). This ensures that the singular vectors form perpendicular directions in wavelength space.\n",
    "\n",
    "The original spectra A, B, C overlap ‚Üí not orthogonal. SVD rotates the axes so that the first three singular vectors are orthogonal directions in wavelength space and finds the directions that best capture the variance. To remain orthogonal, these vectors often develop positive and negative lobes: positive regions ‚Äúcancel out‚Äù negative regions when taking the dot product.\n",
    "\n",
    "- The singular vectors capture variance, not the physical spectra.\n",
    "\n",
    "- The original peak wavelength from singular vectors becomes more complex as the spectral overlap increases.\n",
    "\n",
    "- But you can still determine the number of components and estimate abundances in the SVD space we can also reconstruct the spectra without noise.\n",
    "\n",
    "Next we will see how SVD can be used to **denoise** our spectra.\n",
    "\n",
    "First run the cell below to truncate to the first 3 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "U_k = U[:, :k]        # (200,3)\n",
    "S_k = np.diag(S[:k])  # (3,3)\n",
    "VT_k = VT[:k, :]      # (3,300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c32bee",
   "metadata": {},
   "source": [
    "This is the rank-k approximation, we keep the top k singular vectors:\n",
    "\n",
    "$ A_k \\approx U_k‚ÄãS_kV_k^T$\n",
    "\n",
    "and reconstruct the original spectra from these three singular vectors by taking the dot product (mulitplication) of the left singular vector, the singular values and the right singular vetor.\n",
    "\n",
    "Run the code cell below to calculate the reconstructed spectra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_recon = (U_k @ S_k) @ VT_k  # shape (N, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411db4ae",
   "metadata": {},
   "source": [
    "To ensure the reconstructed spectra are on the correct scale we need to reverse the centering we performed before SVD. To do this we add the mean values back to the reconstructed values using the command:\n",
    "\n",
    ">```python\n",
    "> baseline = np.mean(mixed_abs, axis=0)\n",
    ">spectra_recon_shifted = spectra_recon + baseline\n",
    ">```\n",
    "\n",
    "We must also remove negative values using the numpy clip to force the values to be non-negative (>=0)\n",
    "\n",
    "- Any value below the minimum gets set to the minimum.\n",
    "\n",
    "- Any value above the maximum gets set to the maximum.\n",
    "\n",
    "- Values already inside the range stay unchanged.\n",
    "\n",
    "Modify the code cell below to plot the first 5 original (mixed_abs) and reconstructed (spectra_recon) spectra. You should also calculate the root mean square error ($RMSE$) ```np.sqrt(np.mean(residuals**2))``` this was covered in workshop 4a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### enforce non-negativity (clipping)\n",
    "\n",
    "baseline = np.mean(mixed_abs, axis=0)\n",
    "spectra_recon_shifted = spectra_recon + baseline\n",
    "\n",
    "spectra_recon_nn = np.clip(spectra_recon_shifted, a_min=0, a_max=None)\n",
    "\n",
    "###compute residuals / metrics\n",
    "residual = mixed_abs - spectra_recon\n",
    "rmse_per_sample = ___(___.___(___**___, axis=1))\n",
    "print(\"Overall RMSE:\", ___(___.___(___**___)))\n",
    "\n",
    "# plot original vs denoised for five spectra\n",
    "nplot = ___\n",
    "plt.figure(figsize=(15,20))\n",
    "for ___ in ___(___):\n",
    "    plt.subplot(nplot,1,i+1)\n",
    "    ___.___(___, mixed_abs[___], color='___', label='original', alpha=0.8)\n",
    "    plt.plot(___, spectra_recon_nn[___], color=___', label='reconstructed', lw=1)\n",
    "    plt.ylabel('Intensity')\n",
    "    if i==0:\n",
    "        plt.legend()\n",
    "plt.xlabel('___')\n",
    "plt.ylabel('___')\n",
    "plt.tight_layout()\n",
    "___.___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4252c9",
   "metadata": {},
   "source": [
    "\n",
    "We can see that the first three components capture the shape of the spectra and by reconstructing the spectra using only these components we can remove the noise. Denoising helps us to visualise the underlying spectra more clearly, we can use the peak heights and shapes from our denoised spectra in downstream analysis. \n",
    "\n",
    "Next we'll calculate the relative **abundance** of each chemical in the different mixtures (spectra) to do this we can use the $U$ matrix and the singular values vector $S$.\n",
    "\n",
    "$K = U.S$ gives the abundances for each mixture in the SVD basis but for this calculation we need to perform the SVD on the uncentered matrices.\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scores = estimated abundances in SVD basis\n",
    "k = 3\n",
    "U_k = U[:, :k]        # (200,3)\n",
    "S_k = np.diag(S[:k])  # (3,3)\n",
    "VT_k = VT[:k, :]      # (3,300)\n",
    "\n",
    "abundances_svd = U_k @ S_k  # shape (200,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6ebeb",
   "metadata": {},
   "source": [
    "If we plot the calculated 'SVD-based' abundancies against the weights that we calculated earlier we can see if they correlate.\n",
    "\n",
    "### Rotation\n",
    "\n",
    "Each row of $V^T_k$ is a singular vector across wavelengths. These vectors are orthogonal, so they usually don‚Äôt match the true spectra. We need to rotate the vectors using a rotaton matrix, R to put them in the correct orientation to determine abundancies.\n",
    "\n",
    "$VT_k‚ÄãR‚âàspectra$\n",
    "\n",
    "We have the original spectra and so we can use a least-squares regression ```np.linalg.lstsq``` to find the correct rotation matrix.\n",
    "\n",
    "\n",
    "We use also need to normalaise the weights using the command:\n",
    "\n",
    ">```python\n",
    ">weights_recovered_scaled = weights_recovered / np.max(weights_recovered, axis=0) * np.max(weights, axis=0)\n",
    "> ```\n",
    "\n",
    "¬°¬°¬° IMPORTANT !!! in the rotation command the underscores '_' do not represent a blank. You do not need to modify the cell below, just run it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ececfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotate SVD components to match original spectra\n",
    "\n",
    "rotation, _, _, _ = np.linalg.lstsq(VT_k.T, spectra, rcond=None)  # rotation: (3,3)\n",
    "\n",
    "# Recover weights in original basis\n",
    "weights_recovered = abundances_svd @ rotation  # (200,3)\n",
    "weights_recovered_scaled = weights_recovered / np.max(weights_recovered, axis=0) \n",
    "\n",
    "#Compare recovered vs original\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(weights[:,0], weights_recovered_scaled[:,0], alpha=0.6, label='A')\n",
    "plt.scatter(weights[:,1], weights_recovered_scaled[:,1], alpha=0.6, label='B')\n",
    "plt.scatter(weights[:,2], weights_recovered_scaled[:,2], alpha=0.6, label='C')\n",
    "plt.xlabel(\"Original abundance\")\n",
    "plt.ylabel(\"Recovered abundance\")\n",
    "plt.title(\"Original vs Recovered Chemical Abundances\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd7469",
   "metadata": {},
   "source": [
    "You can see that the weights calcualted from SVD correlate well with the weights used to generate our spectra! This is very useful when analysing a large number of mixtures for example we can use it to automatically detect how mixtures change during a chemical reaction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bcc9e",
   "metadata": {},
   "source": [
    "## Analysing the atmospheric dataset using SVD\n",
    "\n",
    "We will use SVD to analyse the atmospheric dataset, each column in the dataframe contains information about different chemical species. Now we are investigating the most important directions in our data across these variables, rather than across wavelength space that we used in the previous example. \n",
    "\n",
    "The directions with the strongest variance in this space can tell us about relationships between the different variables e.g. are the concentrations of \n",
    "\n",
    "To perform SVD on the atmospheric data we will first convert the clean dataframe ```df_clean``` to a matrix. Run the code cell below to convert and also print out the size of the matrix ```M.shape```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57863d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df_clean.to_numpy()\n",
    "\n",
    "print(\"Data matrix shape:\", M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16054ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Center the data (subtract mean)\n",
    "\n",
    "M_centered = ___ - ___.___(___, axis=0)\n",
    "\n",
    "# Perform SVD\n",
    "\n",
    "___,___, ___ = ___.___.___(___, full_matrices=False)\n",
    "\n",
    "print(\"U shape:\", ___.___)\n",
    "print(\"S shape:\", ___.___)\n",
    "print(\"VT shape:\", ___.___)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eccaf6",
   "metadata": {},
   "source": [
    "#### What do the single values tell us?\n",
    "\n",
    "Single values tell us about the number of dominant components.\n",
    "\n",
    "Use the code cell below to print all of the 100 singular values and generate a scree plot to evaluate the number of dominant components in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Singular values:\", ___[:___])\n",
    "\n",
    "# Each singular value relates to variance as S^2\n",
    "SVbased_variance = ___**___\n",
    "\n",
    "# Make the Scree plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Scree plot\n",
    "___.___(___(___, ___(S)+1), ___, marker='o', label='Variance explained')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Singular Value Index (Mode Number)\")\n",
    "plt.ylabel(\"Singular Value Based Variance \")\n",
    "plt.title(\"SVD Scree Plot\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efb47e",
   "metadata": {},
   "source": [
    "The first mode strongly dominates, this means that most of the day-to-day variability across ALL 55 variables is controlled by ONE underlying atmospheric process. The process corresponding to the largest singular value is typically a strong, coherent process that affects many species at once. In atmospheric observations, a typical dominant process is photochemical activity. \n",
    "\n",
    "However, there are losts of large singular values, they are less clear on the scree plot due to the size of the first value but they are still important. We can plot the scree plot on a logarithmic y-axis ```plt.yscale(\"log\")``` to get more information about the other components. Modify the code cell below to generate the log scree plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8646929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scree plot\n",
    "___.___(___(___, ___(S)+1), ___, marker='o', label='Variance explained')\n",
    "\n",
    "plt.xlabel(\"Singular Value Index (Mode Number)\")\n",
    "plt.ylabel(\"Singular Value Based Variance \")\n",
    "plt.title(\"SVD Scree Plot\")\n",
    "plt.yscale(\"___\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08883544",
   "metadata": {},
   "source": [
    "From the log scree plot you can see that most of the components are large and that most of them contribute to the variance. The last 5 singular vectors are small. If the data had unimportant variables these would be flat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2a2ca",
   "metadata": {},
   "source": [
    "#### What do the shapes of the right singular vectors tell us\n",
    "Plot the right singular vectors of the first 3 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b61b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components=___\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "for ___ in range(___):\n",
    "    ___.___(___[___], marker='o', label=f\"Component {___}\")\n",
    "    \n",
    "plt.xticks(ticks=np.arange(len(column_headers)), labels=column_headers, rotation=90)\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Right singular vector value\")\n",
    "plt.title(\"Right Singular Vectors of Atmospheric Chemistry Data\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84916500",
   "metadata": {},
   "source": [
    "You can see that the directions with the maximum variance are dominated by $HO_2$, $RO_2$ and $CH_3O_2$\n",
    "\n",
    "These are peroxy radicals\n",
    "\n",
    "- $HO_2$: hydroperoxyl radical\n",
    "\n",
    "- $RO_2$: generic organic peroxy radical\n",
    "\n",
    "- $CH_3O_2$: methyl peroxy radical\n",
    "\n",
    "They are key intermediates in atmospheric oxidation of VOCs (volatile organic compounds) and CO. During the day they are generated rapidly by photochemical reactions via OH-initiated oxidation of VOCs. They also react rapidly with NO. This rapid production/removal leads to large fluctuations in their concentrations on short timescales. \n",
    "\n",
    "Small changes in NO, sunlight, or VOC emissions cause big swings in radical concentrations. This makes these species dominate the first principal components (maximum variance directions). Molecules like CO, CH‚ÇÑ, or even many VOCs (such as alkenes, alkanes and aromatics) vary more slowly. This means their variance is smaller, so they contribute less to the directions of maximum variance in SVD.\n",
    "\n",
    "In the code cell below plot the 5th right singular vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e49b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e79c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.plot(___[___], marker='o', label=f\"Component {___}\")\n",
    " #set xticks   \n",
    "___.___(___=___.___(___(____)),____=____, rotation=90)\n",
    "#set x-label as 'Variables'\n",
    "___.___(\"___\")\n",
    "#set y-label as 'Right singular vector value'\n",
    "___.___(\"___\")\n",
    "#set plot title as Right Singular Vectors of Atmospheric Chemistry Data\n",
    "___.___(\"___\")\n",
    "#add legend\n",
    "___.___()\n",
    "#set tight layout \n",
    "___.___()\n",
    "#show plot\n",
    "___.___()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23ea98",
   "metadata": {},
   "source": [
    "We can see that different variables contribute to each right singular vector ($V^T$), these singular vectors give us an indication of which variables change with one another.\n",
    "\n",
    "- Variables with large positive or negative values in the same right singular vector tend to co-vary across the dataset:\n",
    "\n",
    "- If two variables have similar signs and magnitudes ‚Üí they increase/decrease together along that component.\n",
    "\n",
    "- If opposite signs ‚Üí they vary in opposite directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c64633",
   "metadata": {},
   "source": [
    "### What do the left singular vectors tell us?\n",
    "\n",
    "The left singular vectors ($U$) show us the temporal patterns of the SVD component that is how that component changes over time. Use the code cell below to plot the first 5 components and see how they vary with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plot first five left singular vectors\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for k in range(components):\n",
    "    plt.plot(___[:, ___], label=f'U[{___}]')\n",
    "plt.xlabel(\"Time index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Left singular vectors (first few modes)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6428f",
   "metadata": {},
   "source": [
    "We can see from this plot that these components oscillate in time. We can explain this by thinking about photochemistry, during the day photochemical processes will dominate, however, at night other processes will be taking place.\n",
    "\n",
    "We can caluclate the correlation coefficient between each left singular vector ($U$) and each of the variables and display these on a heat map to identify which of the variables most strongly oscillate in time.\n",
    "\n",
    "Run the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9493168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set Parameters \n",
    "n_components = 50  # number of left singular vectors to analyse\n",
    "\n",
    "\n",
    "# Compute correlation matrix ----\n",
    "# rows = SVD components, columns = variables\n",
    "corr_matrix = np.zeros((n_components, len(cols)))\n",
    "\n",
    "for k in range(n_components):\n",
    "    for j, col in enumerate(cols):\n",
    "        corr_matrix[k, j] = np.corrcoef(U[:, k], df_clean[col].values)[0, 1]\n",
    "\n",
    "corr_df = pd.DataFrame(corr_matrix, columns=cols, index=[f'U[{k}]' for k in range(n_components)])\n",
    "\n",
    "# Plot heatmap ----\n",
    "plt.figure(figsize=(20, 6))  # wider figure\n",
    "sns.heatmap(corr_df, cmap='coolwarm', center=0, annot=False, cbar_kws={'label': 'Correlation'})\n",
    "plt.xlabel(\"Chemical species\")\n",
    "plt.ylabel(\"Left singular vectors (U modes)\")\n",
    "plt.title(\"Correlation of left singular vectors with chemical species\")\n",
    "plt.xticks(ticks=np.arange(len(cols)) + 0.5, labels=cols, rotation=90)  # force all labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e4a34",
   "metadata": {},
   "source": [
    "This shows us that the radical species correlate most strongly with the first left singular vector $U[0]$, these are generated by photochemical processes so this makes perfect sense due to the daily oscillations in solar power. We can also that the majority of other species are oscillating in time, this could be due to any number of factors including reacting slowly with products of radical reactions, pollutant emissions, wind etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
